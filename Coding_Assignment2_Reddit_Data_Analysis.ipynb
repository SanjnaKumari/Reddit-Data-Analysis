{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfsmuKdZEVkj"
   },
   "source": [
    "**Importing all required libraries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import nltk\n",
    "\n",
    "# Disable SSL certificate verification temporarily\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "# Reset SSL context to default for safety\n",
    "ssl._create_default_https_context = ssl.create_default_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwxKL3zSJFMY"
   },
   "source": [
    "**Loading the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined_file.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPWXYkX8QJu3"
   },
   "source": [
    "**Task 1: Topic Modeling.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7twup-cQNc6"
   },
   "source": [
    "**1. Preprocess the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def preprocess(self, text):\n",
    "       #Converting to lowercase.\n",
    "        text = text.lower()\n",
    "        #Removing mentions and URLs.\n",
    "        text = re.sub(r'(@\\w+|http\\S+|www\\S+|https\\S+)', '', text)\n",
    "        #Removing hashtags, special characters and numbers.\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        #Removing extra spaces.\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        # Tokenizing text.\n",
    "        tokens = word_tokenize(text)\n",
    "        # Removing stopwords and lemmatize tokens.\n",
    "        cleaned_tokens = [\n",
    "            self.lemmatizer.lemmatize(token)\n",
    "            for token in tokens if token not in self.stop_words\n",
    "        ]\n",
    "        # Joining tokens back into a single string.\n",
    "        return ' '.join(cleaned_tokens)\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    processor = TextPreprocessor()\n",
    "    # Applying preprocessing to each row.\n",
    "    df['cleaned_text'] = df['text'].apply(TextPreprocessor().preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A05JWzlMPVxc"
   },
   "source": [
    "**Comparing original and cleaned text for few rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for original, cleaned in zip(df['text'].head(), df['cleaned_text'].head()):\n",
    "    print(f\"Original: {original}\")\n",
    "    print(f\"Cleaned: {cleaned}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hC6-QFwjQg2k"
   },
   "source": [
    "**2. Apply LDA (Latent Dirichlet Allocation) for Topic Modeling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDATopicModeler:\n",
    "    def __init__(self, cleaned_texts, max_features=1000):\n",
    "        self.cleaned_texts = cleaned_texts\n",
    "        self.max_features = max_features\n",
    "        self.vectorizer = None\n",
    "        self.doc_term_matrix = None\n",
    "        self.dictionary = None\n",
    "        self.corpus = None\n",
    "\n",
    "    # Step 1: Vectorizing the cleaned text using CountVectorizer.\n",
    "    def vectorize_text(self):\n",
    "        self.vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=self.max_features, stop_words='english')\n",
    "        self.doc_term_matrix = self.vectorizer.fit_transform(self.cleaned_texts)\n",
    "        return self.doc_term_matrix\n",
    "\n",
    "    def build_corpus(self):\n",
    "        # Step 2: Tokenizing the cleaned texts and build gensim dictionary and corpus.\n",
    "        tokenized_texts = [text.split() for text in self.cleaned_texts]\n",
    "        self.dictionary = gensim.corpora.Dictionary(tokenized_texts)\n",
    "        self.corpus = [self.dictionary.doc2bow(text) for text in tokenized_texts]\n",
    "\n",
    "    # Step 3: Applying LDA and calculate coherence score.\n",
    "    def lda_with_coherence(self, start=1, end=10):\n",
    "        coherence_scores = []\n",
    "        self.build_corpus()\n",
    "        for n_topics in range(start, end + 1):\n",
    "            lda_model = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "            lda_model.fit(self.doc_term_matrix)\n",
    "            topic_words = self.get_topic_words(lda_model, 10)\n",
    "            coherence = self.compute_coherence(topic_words)\n",
    "            coherence_scores.append((n_topics, coherence))\n",
    "            print(f\"Number of Topics: {n_topics}, Coherence Score: {coherence:.4f}\")\n",
    "        return coherence_scores\n",
    "\n",
    "    # Step 4: Helper to get top words for each topic.\n",
    "    def get_topic_words(self, lda_model, n_top_words):\n",
    "        words = self.vectorizer.get_feature_names_out()\n",
    "        topics = []\n",
    "        for topic_idx, topic in enumerate(lda_model.components_):\n",
    "            topic_top_words = [words[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "            topics.append(topic_top_words)\n",
    "        return topics\n",
    "\n",
    "    # Step 5: Compute coherence.\n",
    "    def compute_coherence(self, topics):\n",
    "        coherence_model = CoherenceModel(topics=topics, texts=[text.split() for text in self.cleaned_texts],\n",
    "                                         dictionary=self.dictionary, coherence='c_v')\n",
    "        return coherence_model.get_coherence()\n",
    "\n",
    "    # Step 6: Finding best topic number, coherence, and selecting the number of topics with the highest coherence.\n",
    "    def find_best_topic_number(self, start=1, end=10):\n",
    "        self.vectorize_text()\n",
    "        coherence_scores = self.lda_with_coherence(start, end)\n",
    "        best_topic = max(coherence_scores, key=lambda x: x[1])\n",
    "        print(f\"Optimal Number of Topics: {best_topic[0]} with Coherence Score: {best_topic[1]:.4f}\")\n",
    "        #return best_topic\n",
    "         # Fitting LDA with optimal number of topics.\n",
    "        optimal_lda_model = LatentDirichletAllocation(n_components=best_topic[0], random_state=24)\n",
    "        optimal_lda_model.fit(self.doc_term_matrix)\n",
    "\n",
    "        # Displaying the topics.\n",
    "        self.display_topics(optimal_lda_model, 10)\n",
    "        return optimal_lda_model, best_topic\n",
    "\n",
    "    #Displaying the top words for each topic.\n",
    "    def display_topics(self, lda_model, n_top_words=10):\n",
    "        words = self.vectorizer.get_feature_names_out()\n",
    "        for topic_idx, topic in enumerate(lda_model.components_):\n",
    "            top_words = [words[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "            print(f\"Topic #{topic_idx + 1}: {', '.join(top_words)}\")\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    #'cleaned_texts' is a list of preprocessed text.\n",
    "    cleaned_texts = df['cleaned_text'].tolist()\n",
    "    lda_modeler = LDATopicModeler(cleaned_texts)\n",
    "    lda_modeler.find_best_topic_number(start=1, end=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BpedMXI_zh3T"
   },
   "source": [
    "**3. Label the Topics.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQ4m1HFxzvd5"
   },
   "source": [
    "Assigning labels to the topics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRY7YqYT0EHp"
   },
   "source": [
    "Topic 1: Personal Experiences and Feelings (words like \"im,\" \"feel,\" \"time\",\"people\").\n",
    "Topic 2: Conflict and Politics (words like \"israel,\" \"palestinian,\" \"hamas,\" \"war\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TopicVisualizer:\n",
    "    def __init__(self, topics, labels):\n",
    "        #param topics: List of topics with top words.\n",
    "        #param labels: List of assigned labels for each topic.\n",
    "        self.topics = topics\n",
    "        self.labels = labels\n",
    "\n",
    "    def generate_word_clouds(self):\n",
    "        #Generating word clouds for each topic.\n",
    "        for idx, topic in enumerate(self.topics):\n",
    "            wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(topic))\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.imshow(wordcloud, interpolation='bilinear')\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"Topic #{idx+1}: {self.labels[idx]}\", fontsize=16)\n",
    "            plt.show()\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Topics and labels based on output.\n",
    "    topics = [\n",
    "        #Topic 1\n",
    "        [\"im\", \"like\", \"know\", \"dont\", \"muslim\", \"want\", \"allah\", \"time\", \"feel\", \"people\"],\n",
    "        #Topic 2\n",
    "        [\"israel\", \"people\", \"palestinian\", \"hamas\", \"israeli\", \"gaza\", \"jew\", \"war\", \"palestine\", \"jewish\"]  # Topic 2\n",
    "    ]\n",
    "    labels = [\"Personal Experiences and Feelings\", \"Conflict and Politics\"]\n",
    "\n",
    "    visualizer = TopicVisualizer(topics, labels)\n",
    "    visualizer.generate_word_clouds()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNk0sA5Y-TO_"
   },
   "source": [
    "**Task 2: Named Entity Recognition (NER).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xF1gdR8aCi0X"
   },
   "source": [
    "**1. NER Extraction using spaCy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YpKI3FZPruDo"
   },
   "source": [
    "**Installing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk import pos_tag, word_tokenize, sent_tokenize\n",
    "from collections import defaultdict\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8Xk8D1InAEA"
   },
   "source": [
    "**Loadinging NLTK VADER.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv('combined_file.csv')\n",
    "text = df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHaFf6tEnRGe"
   },
   "source": [
    "**Initializing sentiment analyzer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Analysis using VADER.\n",
    "vader_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqCUwovnr0Wl"
   },
   "source": [
    "**Defining entities.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_to_analyze = [\"Israel\", \"Hamas\", \"Antony Blinken\", \"Benjamin Netanyahu\", \"Netanyahu\", \"IDF\", \"Israeli Defense Forces\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxqYvfAWnxJo"
   },
   "source": [
    "\n",
    "**Data structures to hold results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_sentiment_scores = defaultdict(list)\n",
    "entity_pos_tags = defaultdict(lambda: defaultdict(list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ersa-L8Gs9pG"
   },
   "source": [
    "**2. Interpretation of Results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R64_ppPhs05E"
   },
   "source": [
    "**POS Tagging.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze texts.\n",
    "def analyze_texts(texts):\n",
    "    for doc in texts:\n",
    "        # Cleaning extra spaces.\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', doc).strip()\n",
    "        # Tokenizing into sentences\n",
    "        sentences = sent_tokenize(cleaned_text)\n",
    "\n",
    "        for sentence in sentences:\n",
    "            for entity in entities_to_analyze:\n",
    "                if entity.lower() in sentence.lower():\n",
    "                    # Sentiment analysis\n",
    "                    sentiment_score = vader_analyzer.polarity_scores(sentence)['compound']\n",
    "                    entity_sentiment_scores[entity].append(sentiment_score)\n",
    "\n",
    "                    # POS tagging\n",
    "                    tokens = word_tokenize(sentence)\n",
    "                    pos_tags = pos_tag(tokens)\n",
    "                    for word, pos in pos_tags:\n",
    "                        if pos.startswith('NN'):\n",
    "                            entity_pos_tags[entity]['nouns'].append(word)\n",
    "                        elif pos.startswith('VB'):\n",
    "                            entity_pos_tags[entity]['verbs'].append(word)\n",
    "                        elif pos.startswith('JJ'):\n",
    "                            entity_pos_tags[entity]['adjectives'].append(word)\n",
    "\n",
    "# Performing analysis.\n",
    "analyze_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating and displaying average sentiment scores.\n",
    "avg_sentiment_results = {\n",
    "    entity: sum(scores) / len(scores) if scores else 0\n",
    "    for entity, scores in entity_sentiment_scores.items()\n",
    "}\n",
    "\n",
    "# Displaying results.\n",
    "print(\"\\n=== Entity Sentiment Summary ===\\n\")\n",
    "print(f\"{'Entity':<25} | {'Average Sentiment Score':>25}\")\n",
    "print(\"-\" * 55)\n",
    "for entity, avg_score in avg_sentiment_results.items():\n",
    "    print(f\"{entity:<25} | {avg_score:>25.4f}\")\n",
    "print(\"\\n\" + \"=\" * 55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCkaV5FBtLdt"
   },
   "source": [
    "Visualization of Sentiment Distribution per Entity and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization 1: Sentiment Distribution per Entity\n",
    "def plot_sentiment_distribution():\n",
    "    sentiment_data = []\n",
    "    for entity, scores in entity_sentiment_scores.items():\n",
    "        for score in scores:\n",
    "            sentiment_data.append({\"Entity\": entity, \"Sentiment Score\": score})\n",
    "    sentiment_df = pd.DataFrame(sentiment_data)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x=\"Entity\", y=\"Sentiment Score\", data=sentiment_df)\n",
    "    plt.title(\"Sentiment Score Distribution per Entity\", fontsize=16)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Visualization 2: POS Tag Count per Entity\n",
    "def plot_pos_tag_counts():\n",
    "    pos_data = []\n",
    "    for entity, pos_tags in entity_pos_tags.items():\n",
    "        for tag_type, words in pos_tags.items():\n",
    "            pos_data.append({\"Entity\": entity, \"POS Tag\": tag_type, \"Count\": len(words)})\n",
    "\n",
    "    pos_df = pd.DataFrame(pos_data)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=\"Entity\", y=\"Count\", hue=\"POS Tag\", data=pos_df)\n",
    "    plt.title(\"POS Tag Counts per Entity\", fontsize=16)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhzQPxAbtDgx"
   },
   "source": [
    "**Word Cloud Visualization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate word clouds.\n",
    "def generate_wordcloud(words, title):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(words))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Generating word clouds\n",
    "print(\"\\nGenerating Visualizations:\")\n",
    "for entity in entities_to_analyze:\n",
    "    print(f\"Word Cloud for {entity}\")\n",
    "    words_combined = (\n",
    "        entity_pos_tags[entity]['nouns'] +\n",
    "        entity_pos_tags[entity]['verbs'] +\n",
    "        entity_pos_tags[entity]['adjectives']\n",
    "    )\n",
    "    generate_wordcloud(words_combined, f\"{entity} - Verbs, Nouns, and Adjectives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling visualizations .\n",
    "plot_sentiment_distribution()\n",
    "plot_pos_tag_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOeD_vx6tk6s"
   },
   "source": [
    "**Task 3: Predicting Score for Each Reddit Post.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDLPXuy_uzA0"
   },
   "source": [
    "**Importing all required libraries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from gensim.models import Word2Vec\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset.\n",
    "df = pd.read_csv('combined_file.csv')\n",
    "\n",
    "# Combining title and text for better context.\n",
    "df['combined_text'] = df['title'] + \" \" + df['text']\n",
    "\n",
    "# Preprocess the combined text\n",
    "df['cleaned_text'] = df['combined_text'].apply(lambda x: re.sub(r'\\W+', ' ', x.lower().strip()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdgsGja5wpoE"
   },
   "source": [
    "**Feature Selection.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDATopicModeler:\n",
    "    def __init__(self, cleaned_texts, max_features=1000):\n",
    "        self.cleaned_texts = cleaned_texts\n",
    "        self.max_features = max_features\n",
    "        self.vectorizer = None\n",
    "        self.doc_term_matrix = None\n",
    "        self.dictionary = None\n",
    "        self.corpus = None\n",
    "\n",
    "    # Step 1: Vectorizing the cleaned text using CountVectorizer.\n",
    "    def vectorize_text(self):\n",
    "        self.vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=self.max_features, stop_words='english')\n",
    "        self.doc_term_matrix = self.vectorizer.fit_transform(self.cleaned_texts)\n",
    "        return self.doc_term_matrix\n",
    "\n",
    "    def build_corpus(self):\n",
    "        # Step 2: Tokenizing the cleaned texts and build gensim dictionary and corpus.\n",
    "        tokenized_texts = [text.split() for text in self.cleaned_texts]\n",
    "        self.dictionary = gensim.corpora.Dictionary(tokenized_texts)\n",
    "        self.corpus = [self.dictionary.doc2bow(text) for text in tokenized_texts]\n",
    "\n",
    "    # Step 3: Applying LDA and calculate coherence score.\n",
    "    def lda_with_coherence(self, start=1, end=10):\n",
    "        coherence_scores = []\n",
    "        self.build_corpus()\n",
    "        for n_topics in range(start, end + 1):\n",
    "            lda_model = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "            lda_model.fit(self.doc_term_matrix)\n",
    "            topic_words = self.get_topic_words(lda_model, 10)\n",
    "            coherence = self.compute_coherence(topic_words)\n",
    "            coherence_scores.append((n_topics, coherence))\n",
    "            print(f\"Number of Topics: {n_topics}, Coherence Score: {coherence:.4f}\")\n",
    "        return coherence_scores\n",
    "\n",
    "    # Step 4: Helper to get top words for each topic.\n",
    "    def get_topic_words(self, lda_model, n_top_words):\n",
    "        words = self.vectorizer.get_feature_names_out()\n",
    "        topics = []\n",
    "        for topic_idx, topic in enumerate(lda_model.components_):\n",
    "            topic_top_words = [words[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "            topics.append(topic_top_words)\n",
    "        return topics\n",
    "\n",
    "    # Step 5: Compute coherence.\n",
    "    def compute_coherence(self, topics):\n",
    "        coherence_model = CoherenceModel(topics=topics, texts=[text.split() for text in self.cleaned_texts],\n",
    "                                         dictionary=self.dictionary, coherence='c_v')\n",
    "        return coherence_model.get_coherence()\n",
    "\n",
    "    # Step 6: Finding best topic number, coherence, and selecting the number of topics with the highest coherence.\n",
    "    def find_best_topic_number(self, start=1, end=10):\n",
    "        self.vectorize_text()\n",
    "        coherence_scores = self.lda_with_coherence(start, end)\n",
    "        best_topic = max(coherence_scores, key=lambda x: x[1])\n",
    "        print(f\"Optimal Number of Topics: {best_topic[0]} with Coherence Score: {best_topic[1]:.4f}\")\n",
    "        #return best_topic\n",
    "         # Fitting LDA with optimal number of topics.\n",
    "        optimal_lda_model = LatentDirichletAllocation(n_components=best_topic[0], random_state=24)\n",
    "        optimal_lda_model.fit(self.doc_term_matrix)\n",
    "\n",
    "        # Displaying the topics.\n",
    "        self.display_topics(optimal_lda_model, 10)\n",
    "        return optimal_lda_model, best_topic\n",
    "\n",
    "    #Displaying the top words for each topic.\n",
    "    def display_topics(self, lda_model, n_top_words=10):\n",
    "        words = self.vectorizer.get_feature_names_out()\n",
    "        for topic_idx, topic in enumerate(lda_model.components_):\n",
    "            top_words = [words[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "            print(f\"Topic #{topic_idx + 1}: {', '.join(top_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Topic Modeling using LDA.\n",
    "cleaned_texts = df['cleaned_text'].tolist()\n",
    "lda_modeler = LDATopicModeler(cleaned_texts)\n",
    "optimal_lda_model, best_topic = lda_modeler.find_best_topic_number(start=1, end=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating topic features.\n",
    "# Extract LDA topic distributions for each document\n",
    "lda_features = optimal_lda_model.transform(lda_modeler.doc_term_matrix)\n",
    "lda_df = pd.DataFrame(lda_features, columns=[f'topic_{i}' for i in range(lda_features.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQaSQnjWa8hk"
   },
   "source": [
    "Step 2: Sentence Embeddings using Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing cleaned text.\n",
    "tokenized_texts = df['cleaned_text'].apply(lambda x: x.split())\n",
    "\n",
    "# Training Word2Vec model.\n",
    "word2vec_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Getting average Word2Vec embeddings for each document.\n",
    "word2vec_embeddings = df['cleaned_text'].apply(\n",
    "    lambda x: np.mean([word2vec_model.wv[word] for word in x.split() if word in word2vec_model.wv] or [np.zeros(100)], axis=0)\n",
    ")\n",
    "\n",
    "# Converting to DataFrame\n",
    "word2vec_df = pd.DataFrame(word2vec_embeddings.tolist(), columns=[f'w2v_emb_{i}' for i in range(100)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juDBjiLqbV-i"
   },
   "source": [
    "Step 3: Combining LDA and Embedding Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining LDA features with Word2Vec embeddings.\n",
    "combined_features = pd.concat([lda_df, word2vec_df], axis=1)  # Replace `word2vec_df` with `glove_df` if using GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable.\n",
    "target = df['score']\n",
    "\n",
    "# Standardize Features.\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(combined_features)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7tR2EaZbkYi"
   },
   "source": [
    "**Step 4: Model Training and Evaluation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM Model\n",
    "# svm_model = SVR(kernel='linear')\n",
    "# svm_model.fit(X_train, y_train)\n",
    "# svm_predictions = svm_model.predict(X_test)\n",
    "# svm_mse = mean_squared_error(y_test, svm_predictions)\n",
    "# print(f\"SVM Mean Squared Error: {svm_mse:.4f}\")\n",
    "\n",
    "# Train SVM model with RBF kernel\n",
    "svm_model = SVR(kernel='rbf', C=1.0, gamma='scale')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "svm_mse = mean_squared_error(y_test, svm_predictions)\n",
    "print(f\"SVM with RBF Kernel MSE: {svm_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost Model\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=24)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "xgb_mse = mean_squared_error(y_test, xgb_predictions)\n",
    "print(f\"XGBoost Mean Squared Error: {xgb_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variance of the score column\n",
    "score_variance = df['score'].var()\n",
    "\n",
    "print(f\"Variance of the score column: {score_variance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = svm_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = xgb_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
